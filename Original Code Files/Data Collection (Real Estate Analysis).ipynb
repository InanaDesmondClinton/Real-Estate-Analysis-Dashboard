{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecticut - 09\n",
    "\n",
    "09000        Connecticut\n",
    "09001        Fairfield County\n",
    "09003        Hartford County\n",
    "09005        Litchfield County\n",
    "09007        Middlesex County\n",
    "09009        New Haven County\n",
    "09011        New London County\n",
    "09013        Tolland County\n",
    "09015        Windham County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "09000\n",
    "09001        Fairfield County\n",
    "09003        Hartford County\n",
    "09005        Litchfield County\n",
    "09007        Middlesex County\n",
    "09009        New Haven County\n",
    "09011        New London County\n",
    "09013        Tolland County\n",
    "09015        Windham County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Louisiana - 22\n",
    "\n",
    "22000        Louisiana\n",
    "22001        Acadia Parish\n",
    "22003        Allen Parish\n",
    "22005        Ascension Parish\n",
    "22007        Assumption Parish\n",
    "22009        Avoyelles Parish\n",
    "22011        Beauregard Parish\n",
    "22013        Bienville Parish\n",
    "22015        Bossier Parish\n",
    "22017        Caddo Parish\n",
    "22019        Calcasieu Parish\n",
    "22021        Caldwell Parish\n",
    "22023        Cameron Parish\n",
    "22025        Catahoula Parish\n",
    "22027        Claiborne Parish\n",
    "22029        Concordia Parish\n",
    "22031        De Soto Parish\n",
    "22033        East Baton Rouge Parish\n",
    "22035        East Carroll Parish\n",
    "22037        East Feliciana Parish\n",
    "22039        Evangeline Parish\n",
    "22041        Franklin Parish\n",
    "22043        Grant Parish\n",
    "22045        Iberia Parish\n",
    "22047        Iberville Parish\n",
    "22049        Jackson Parish\n",
    "22051        Jefferson Parish\n",
    "22053        Jefferson Davis Parish\n",
    "22055        Lafayette Parish\n",
    "22057        Lafourche Parish\n",
    "22059        La Salle Parish\n",
    "22061        Lincoln Parish\n",
    "22063        Livingston Parish\n",
    "22065        Madison Parish\n",
    "22067        Morehouse Parish\n",
    "22069        Natchitoches Parish\n",
    "22071        Orleans Parish\n",
    "22073        Ouachita Parish\n",
    "22075        Plaquemines Parish\n",
    "22077        Pointe Coupee Parish\n",
    "22079        Rapides Parish\n",
    "22081        Red River Parish\n",
    "22083        Richland Parish\n",
    "22085        Sabine Parish\n",
    "22087        St. Bernard Parish\n",
    "22089        St. Charles Parish\n",
    "22091        St. Helena Parish\n",
    "22093        St. James Parish\n",
    "22095        St. John the Baptist Parish\n",
    "22097        St. Landry Parish\n",
    "22099        St. Martin Parish\n",
    "22101        St. Mary Parish\n",
    "22103        St. Tammany Parish\n",
    "22105        Tangipahoa Parish\n",
    "22107        Tensas Parish\n",
    "22109        Terrebonne Parish\n",
    "22111        Union Parish\n",
    "22113        Vermilion Parish\n",
    "22115        Vernon Parish\n",
    "22117        Washington Parish\n",
    "22119        Webster Parish\n",
    "22121        West Baton Rouge Parish\n",
    "22123        West Carroll Parish\n",
    "22125        West Feliciana Parish\n",
    "22127        Winn Parish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENSUS_API_KEY=\"fd784fba6127058c89322a9aca4e9dcde538fa73\"\n",
    "FBI_CRIME_API_KEY = \"v85tAMbzh1QdhcKXWlIuQWissupDCmVXIGuPtpvI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for Connecticut in 2024: 404 <!doctype html><html lang=\"en\"><head><title>HTTP Status 404 ? Not Found</title><style type=\"text/css\">body {font-family:Tahoma,Arial,sans-serif;} h1, h2, h3, b {color:white;background-color:#525D76;} h1 {font-size:22px;} h2 {font-size:16px;} h3 {font-size:14px;} p {font-size:12px;} a {color:black;} .line {height:1px;background-color:#525D76;border:none;}</style></head><body><h1>HTTP Status 404 ? Not Found</h1></body></html>\n",
      "Error fetching data for Louisiana in 2024: 404 <!doctype html><html lang=\"en\"><head><title>HTTP Status 404 ? Not Found</title><style type=\"text/css\">body {font-family:Tahoma,Arial,sans-serif;} h1, h2, h3, b {color:white;background-color:#525D76;} h1 {font-size:22px;} h2 {font-size:16px;} h3 {font-size:14px;} p {font-size:12px;} a {color:black;} .line {height:1px;background-color:#525D76;border:none;}</style></head><body><h1>HTTP Status 404 ? Not Found</h1></body></html>\n",
      "Error fetching data for Connecticut in 2025: 404 <!doctype html><html lang=\"en\"><head><title>HTTP Status 404 ? Not Found</title><style type=\"text/css\">body {font-family:Tahoma,Arial,sans-serif;} h1, h2, h3, b {color:white;background-color:#525D76;} h1 {font-size:22px;} h2 {font-size:16px;} h3 {font-size:14px;} p {font-size:12px;} a {color:black;} .line {height:1px;background-color:#525D76;border:none;}</style></head><body><h1>HTTP Status 404 ? Not Found</h1></body></html>\n",
      "Error fetching data for Louisiana in 2025: 404 <!doctype html><html lang=\"en\"><head><title>HTTP Status 404 ? Not Found</title><style type=\"text/css\">body {font-family:Tahoma,Arial,sans-serif;} h1, h2, h3, b {color:white;background-color:#525D76;} h1 {font-size:22px;} h2 {font-size:16px;} h3 {font-size:14px;} p {font-size:12px;} a {color:black;} .line {height:1px;background-color:#525D76;border:none;}</style></head><body><h1>HTTP Status 404 ? Not Found</h1></body></html>\n"
     ]
    }
   ],
   "source": [
    "# Base URLs\n",
    "CENSUS_BASE_URL = \"https://api.census.gov/data/2022/acs/acs5\"\n",
    "FBI_CRIME_API = \"https://api.usa.gov/crime/fbi/sapi/\"\n",
    "\n",
    "# States to Collect Data From\n",
    "STATE_FIPS = {\"Connecticut\": \"09\", \"Louisiana\": \"22\"}\n",
    "\n",
    "# Variables for Census API\n",
    "# Variables for Census API\n",
    "CENSUS_VARIABLES = [\n",
    "    # Demographics\n",
    "    \"B01003_001E\", \"B01002_001E\", \"B25010_001E\", \"B15003_017E\", \"B15003_022E\", \n",
    "    \"B02001_002E\", \"B02001_003E\", \"B03003_003E\", \"B01001_002E\", \"B01001_026E\", \n",
    "    \"B01001_003E\", \"B01001_007E\", \"B01001_012E\", \"B01001_020E\", \n",
    "    # Housing\n",
    "    \"B25001_001E\", \"B25002_002E\", \"B25002_003E\", \"B25003_002E\", \"B25003_003E\", \n",
    "    \"B25077_001E\", \"B25064_001E\", \"B25024_002E\", \"B25024_003E\", \"B25024_004E\", \n",
    "    \"B25034_001E\", \"B25081_002E\", \"B25081_003E\", \"B25004_001E\", \"B25003_001E\",\n",
    "    # Economic Data\n",
    "    \"B19013_001E\", \"B19301_001E\", \"B23025_005E\", \"B23025_002E\", \"B17001_002E\", \"B17001_001E\", \n",
    "    \"C24010_001E\", \"B19057_002E\", \"B08303_001E\", \"B08101_001E\"\n",
    "]\n",
    "\n",
    "# Function to fetch Census data\n",
    "\n",
    "def fetch_census_data(county=\"*\"):\n",
    "    data_frames = []\n",
    "    for year in range(2015, 2026):\n",
    "        for state, fips in STATE_FIPS.items():\n",
    "            base_url = f\"https://api.census.gov/data/{year}/acs/acs5\"\n",
    "            params = {\n",
    "                \"get\": f\"NAME,{','.join(CENSUS_VARIABLES)}\",\n",
    "                \"for\": f\"county:{county}\",\n",
    "                \"in\": f\"state:{fips}\",\n",
    "                \"key\": CENSUS_API_KEY\n",
    "            }\n",
    "            response = requests.get(base_url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                    df = pd.DataFrame(data[1:], columns=data[0])\n",
    "                    df[\"State\"] = state\n",
    "                    df[\"Year\"] = year\n",
    "                    data_frames.append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing data for {state} in {year}: {e}\")\n",
    "            else:\n",
    "                print(f\"Error fetching data for {state} in {year}: {response.status_code} {response.text}\")\n",
    "    return pd.concat(data_frames, ignore_index=True) if data_frames else pd.DataFrame()\n",
    "\n",
    "# Fetch Data\n",
    "demographics_housing_economic_data = fetch_census_data()\n",
    "\n",
    "if not demographics_housing_economic_data.empty:\n",
    "    demographics_housing_economic_data.to_csv(\"census_real_estate_data_county.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Demographic Variables (ACS 5-Year Estimates from U.S. Census API)\n",
    "Population Growth Rate: (B01003_001E)\n",
    "Median Age: (B01002_001E)\n",
    "Household Size: (B25010_001E)\n",
    "Educational Attainment:\n",
    "Less than High School: (B15003_002E - B15003_016E)\n",
    "High School Graduate: (B15003_017E)\n",
    "Bachelor's Degree and Higher: (B15003_022E - B15003_025E)\n",
    "Race & Ethnicity:\n",
    "White: (B02001_002E)\n",
    "Black or African American: (B02001_003E)\n",
    "Hispanic or Latino: (B03003_003E)\n",
    "Gender Distribution:\n",
    "Male: (B01001_002E)\n",
    "Female: (B01001_026E)\n",
    "Age Groups (Key for Market Segmentation):\n",
    "Under 18: (B01001_003E to B01001_006E + B01001_027E to B01001_030E)\n",
    "18-34: (B01001_007E to B01001_011E + B01001_031E to B01001_035E)\n",
    "35-64: (B01001_012E to B01001_019E + B01001_036E to B01001_043E)\n",
    "65 and Older: (B01001_020E to B01001_025E + B01001_044E to B01001_049E)\n",
    "2. Housing Market Variables (ACS 5-Year Estimates)\n",
    "Total Housing Units: (B25001_001E)\n",
    "Occupied vs. Vacant Housing Units:\n",
    "Occupied: (B25002_002E)\n",
    "Vacant: (B25002_003E)\n",
    "Homeownership Rate: (B25003_002E / B25003_001E)\n",
    "Renter-Occupied vs. Owner-Occupied Housing Units: (B25003_001E)\n",
    "Median Home Value: (B25077_001E)\n",
    "Median Gross Rent: (B25064_001E)\n",
    "Housing Structure Type: (Useful for investor decisions)\n",
    "Single-Family Detached: (B25024_002E)\n",
    "Multi-Family (2-4 units): (B25024_003E)\n",
    "Multi-Family (5+ units): (B25024_004E)\n",
    "Year Structure Built: (B25034_001E)\n",
    "Units with Mortgage vs. Owned Free & Clear: (B25081_002E & B25081_003E)\n",
    "Home Vacancy Rate: (B25004_001E)\n",
    "Housing Affordability Index (Computed Using Median Income vs. Rent/Value)\n",
    "3. Economic & Employment Data (ACS 5-Year Estimates)\n",
    "Median Household Income: (B19013_001E)\n",
    "Per Capita Income: (B19301_001E)\n",
    "Unemployment Rate: (B23025_005E / B23025_002E)\n",
    "Poverty Rate: (B17001_002E / B17001_001E)\n",
    "Employment by Industry: (C24010_001E)\n",
    "Percentage of Households with Public Assistance: (B19057_002E)\n",
    "Transportation & Commute Time (Indicator for Accessibility):\n",
    "Mean Travel Time to Work: (B08303_001E)\n",
    "Mode of Transportation (Public, Car, etc.): (B08101_001E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching Old Saybrook Connecticut house prices: received 429 HTTP response\n",
      "Error fetching Orange Connecticut house prices: received 429 HTTP response\n",
      "Error fetching Orange Connecticut real estate: received 429 HTTP response\n",
      "Error fetching Orange Connecticut real estate: received 429 HTTP response\n",
      "Error fetching Orange Connecticut house prices: received 429 HTTP response\n",
      "Error fetching Old Saybrook Connecticut house prices: received 429 HTTP response\n",
      "Error fetching Epps Louisiana house prices: received 429 HTTP response\n",
      "Error fetching Epps Louisiana real estate: received 429 HTTP response\n",
      "Error fetching Erath Louisiana real estate: received 429 HTTP response\n",
      "Error fetching Erath Louisiana house prices: received 429 HTTP response\n",
      "Error fetching Erath Louisiana real estate: received 429 HTTP response\n",
      "Error fetching Erath Louisiana real estate: received 429 HTTP response\n",
      "Error fetching Erath Louisiana house prices: received 429 HTTP response\n",
      "Error fetching Leesville Louisiana real estate: received 429 HTTP response\n",
      "Error fetching Leesville Louisiana real estate: received 429 HTTP response\n",
      "Error fetching Sulphur Louisiana house prices: received 429 HTTP response\n",
      "Error fetching Sulphur Louisiana real estate: received 429 HTTP response\n",
      "Error fetching Sulphur Louisiana real estate: received 429 HTTP response\n",
      "Error fetching Sulphur Louisiana house prices: received 429 HTTP response\n",
      "Error fetching Sulphur Louisiana house prices: received 429 HTTP response\n",
      "Error fetching Tallulah Louisiana real estate: received 429 HTTP response\n",
      "Error fetching Tallulah Louisiana house prices: received 429 HTTP response\n",
      "Error fetching Tallulah Louisiana real estate: received 429 HTTP response\n",
      "Reddit data collection complete. 3978 posts saved.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import time\n",
    "from datetime import datetime\n",
    "from threading import Lock\n",
    "\n",
    "# Reddit API Credentials\n",
    "from keys_secrets import reddit_client_id, reddit_client_secret, reddit_password, reddit_user_agent, reddit_username\n",
    "\n",
    "# Reddit API authentication\n",
    "reddit = praw.Reddit(\n",
    "    client_id=reddit_client_id,\n",
    "    client_secret=reddit_client_secret,\n",
    "    #password=reddit_password,\n",
    "    user_agent=reddit_user_agent,\n",
    "    #username=reddit_username\n",
    ")\n",
    "\n",
    "# States and Counties\n",
    "CITIES = {\n",
    "    \"Connecticut\": [\n",
    "    \"Ansonia\", \"Avon\", \"Berlin\", \"Bethel\", \"Bloomfield\", \"Branford\", \"Bridgeport\", \"Bristol\", \n",
    "    \"Brookfield\", \"Canton\", \"Cheshire\", \"Clinton\", \"Coventry\", \"Cromwell\", \"Danbury\", \"Darien\", \n",
    "    \"Derby\", \"East Hampton\", \"East Hartford\", \"East Haven\", \"Easton\", \"East Windsor\", \"Enfield\", \n",
    "    \"Fairfield\", \"Farmington\", \"Glastonbury\", \"Granby\", \"Greenwich\", \"Groton\", \"Groton Long Point\", \n",
    "    \"Groton Town\", \"Guilford\", \"Hamden\", \"Hartford\", \"Madison\", \"Manchester\", \"Meriden\", \"Middlebury\", \n",
    "    \"Middletown\", \"Milford\", \"Monroe\", \"Naugatuck\", \"New Britain\", \"New Canaan\", \"Newington\", \n",
    "    \"New London\", \"New Milford\", \"Newtown\", \"North Branford\", \"North Haven\", \"Norwalk\", \"Norwich\", \n",
    "    \"Old Saybrook\", \"Orange\", \"Plainfield\", \"Plainville\", \"Plymouth\", \"Portland\", \"Putnam\", \n",
    "    \"Redding\", \"Ridgefield\", \"Rocky Hill\", \"Seymour\", \"Shelton\", \"Simsbury\", \"Southington\", \n",
    "    \"South Windsor\", \"Stamford\", \"Stonington\", \"Stratford\", \"Suffield\", \"Thomaston\", \"Torrington\", \n",
    "    \"Trumbull\", \"Vernon\", \"Wallingford\", \"Waterbury\", \"Waterford\", \"Watertown\", \"West Hartford\", \n",
    "    \"West Haven\", \"Weston\", \"Westport\", \"Wethersfield\", \"Willimantic\", \"Wilton\", \"Winchester\", \n",
    "    \"Windsor\", \"Windsor Locks\", \"Wolcott\", \"Woodbridge\"\n",
    "],\n",
    "    \"Louisiana\": [\n",
    "    \"Abbeville\", \"Addis\", \"Alexandria\", \"Baldwin\", \"Ball\", \"Basile\", \"Bastrop\", \"Baton Rouge\", \n",
    "    \"Bernice\", \"Berwick\", \"Blanchard\", \"Bogalusa\", \"Bossier City\", \"Breaux Bridge\", \"Broussard\", \n",
    "    \"Brusly\", \"Bunkie\", \"Carencro\", \"Church Point\", \"Clarence\", \"Clinton\", \"Cottonport\", \n",
    "    \"Coushatta\", \"Covington\", \"Crowley\", \"Denham Springs\", \"De Quincy\", \"De Ridder\", \"Epps\", \n",
    "    \"Erath\", \"Eunice\", \"Farmerville\", \"Ferriday\", \"Fisher\", \"Florien\", \"Folsom\", \"Franklin\", \n",
    "    \"Franklinton\", \"French Settlement\", \"Georgetown\", \"Golden Meadow\", \"Gonzales\", \"Gramercy\", \n",
    "    \"Greenwood\", \"Gretna\", \"Hammond\", \"Harahan\", \"Haughton\", \"Houma\", \"Ida\", \"Independence\", \n",
    "    \"Iowa\", \"Jena\", \"Jennings\", \"Kaplan\", \"Kentwood\", \"Killian\", \"Kinder\", \"Krotz Springs\", \n",
    "    \"Lafayette\", \"Lake Arthur\", \"Lake Charles\", \"Lake Providence\", \"Leesville\", \"Lutcher\", \n",
    "    \"Mandeville\", \"Mansfield\", \"Many\", \"Marion\", \"Marksville\", \"Minden\", \"Monroe\", \"Montgomery\", \n",
    "    \"Montpelier\", \"Moreauville\", \"Morgan City\", \"Natchitoches\", \"New Orleans\", \"Norwood\", \n",
    "    \"Oil City\", \"Olla\", \"Opelousas\", \"Patterson\", \"Pearl River\", \"Pineville\", \"Pollock\", \n",
    "    \"Ponchatoula\", \"Port Allen\", \"Port Vincent\", \"Rayne\", \"Ruston\", \"Scott\", \"Shreveport\", \n",
    "    \"Sibley\", \"Slidell\", \"Springhill\", \"Sulphur\", \"Tallulah\", \"Thibodaux\", \"Tickfaw\", \"Vidalia\", \n",
    "    \"Ville Platte\", \"Vinton\", \"Walker\", \"West Monroe\", \"Westwego\", \"White Castle\", \"Wilson\", \n",
    "    \"Winnfield\", \"Zachary\"\n",
    "]\n",
    "}\n",
    "# Years Range\n",
    "YEARS = list(range(2019, 2024))  # 2019-2023\n",
    "\n",
    "# Search Terms\n",
    "SEARCH_TERMS = [\"real estate\", \"house prices\"]\n",
    "\n",
    "# Global Variables\n",
    "MAX_POSTS = 5000\n",
    "TOTAL_COMBOS = sum(len(cities) for cities in CITIES.values()) * len(YEARS) * len(SEARCH_TERMS)\n",
    "POSTS_PER_COMBO = MAX_POSTS // TOTAL_COMBOS  # Ensure even distribution\n",
    "COLLECTED_POSTS = 0\n",
    "LOCK = Lock()  # Prevent race conditions in multi-threading\n",
    "\n",
    "# Data Storage\n",
    "collected_data = []\n",
    "\n",
    "# Function to Fetch Data\n",
    "def fetch_for_query(state, city, year, term):\n",
    "    global COLLECTED_POSTS\n",
    "    if COLLECTED_POSTS >= MAX_POSTS:\n",
    "        return  # Stop fetching once we reach the limit\n",
    "\n",
    "    query = f\"{city} {state} {term}\"\n",
    "    try:\n",
    "        posts_fetched = 0\n",
    "        for submission in reddit.subreddit(\"realestate\").search(query, sort=\"new\", time_filter=\"all\", limit=POSTS_PER_COMBO):\n",
    "            with LOCK:\n",
    "                if COLLECTED_POSTS >= MAX_POSTS:\n",
    "                    break  # Stop if we hit the max limit\n",
    "                \n",
    "                # Save Post Data\n",
    "                post_data = {\n",
    "                    \"title\": submission.title,\n",
    "                    \"content\": submission.selftext,\n",
    "                    \"score\": submission.score,\n",
    "                    \"url\": submission.url,\n",
    "                    \"created_utc\": submission.created_utc,\n",
    "                    \"city\": city,\n",
    "                    \"state\": state,\n",
    "                    \"year\": year,\n",
    "                    \"upvote_ratio\": submission.upvote_ratio,\n",
    "                    \"flair\": submission.link_flair_text if submission.link_flair_text else \"None\",\n",
    "                    \"date_posted\": datetime.fromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    \"comments_count\": submission.num_comments,\n",
    "                    \"awards_count\": len(submission.all_awardings),\n",
    "                }\n",
    "\n",
    "                # Fetch comments (limit to avoid too much data)\n",
    "                submission.comments.replace_more(limit=0)\n",
    "                comments = [comment.body for comment in submission.comments.list()[:5]]\n",
    "                post_data[\"comments\"] = \" || \".join(comments)\n",
    "\n",
    "                # Append Data\n",
    "                collected_data.append(post_data)\n",
    "                COLLECTED_POSTS += 1\n",
    "                posts_fetched += 1\n",
    "\n",
    "            if posts_fetched >= POSTS_PER_COMBO:\n",
    "                break  # Stop fetching for this query\n",
    "\n",
    "        # Apply Rate Limiting\n",
    "        if COLLECTED_POSTS % 200 == 0:\n",
    "            time.sleep(5)  # Pause to avoid API limit\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {query}: {e}\")\n",
    "\n",
    "# Multi-threaded Execution\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for state, cities in CITIES.items():\n",
    "        for city in cities:\n",
    "            for year in YEARS:\n",
    "                for term in SEARCH_TERMS:\n",
    "                    if COLLECTED_POSTS >= MAX_POSTS:\n",
    "                        break\n",
    "                    futures.append(executor.submit(fetch_for_query, state, city, year, term))\n",
    "\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(collected_data)\n",
    "if not df.empty:\n",
    "    df.to_csv(\"reddit_real_estate_data_balanced.csv\", index=False)\n",
    "\n",
    "print(f\"Reddit data collection complete. {COLLECTED_POSTS} posts saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
